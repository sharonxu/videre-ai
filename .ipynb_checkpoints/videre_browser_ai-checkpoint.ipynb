{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d448e24-3d65-4add-b841-0fb347b1e1e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'perplexipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mperplexipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PerplexityClient\n\u001b[1;32m      7\u001b[0m client \u001b[38;5;241m=\u001b[39m anthropic\u001b[38;5;241m.\u001b[39mAnthropic()\n\u001b[1;32m      8\u001b[0m perplexity_client \u001b[38;5;241m=\u001b[39m PerplexityClient()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'perplexipy'"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from perplexipy import PerplexityClient\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "perplexity_client = PerplexityClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd69fe9b-b135-4db3-bd0f-653be88d9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.query('What is the meaning of 42?') \\\n",
    "for result in client.queryStreamable('List of all US presidents'): \\\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa3308-3489-4795-b10a-748f8515a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_website(url):\n",
    "    # Send a GET request to the website\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract all text from the parsed HTML\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "        \n",
    "        return text\n",
    "    else:\n",
    "        return f\"Failed to retrieve the webpage. Status code: {response.status_code}\"\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.cbsnews.com/news/israel-lebanon-hezbollah-hassan-nasrallah-killed-beirut-strike/\"\n",
    "scraped_text = scrape_website(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae1e1b-4127-4057-91ae-72ed98ae9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\"\n",
    "\n",
    "def get_completion(client, prompt, max_tokens=2048):\n",
    "    return client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        messages=[{\n",
    "            \"role\": 'user', \"content\":  prompt\n",
    "        }]\n",
    "    ).content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae08e0-7721-4416-932b-e48e06654190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(client, text, max_tokens=4096):\n",
    "    return get_completion(\n",
    "        client,\n",
    "        f\"\"\"Here are the contents of a website: <website>{text}</website>\n",
    "    \n",
    "        Please do the following:\n",
    "        1. Summarize the text of the website.\n",
    "        2. Note any possible biases or misinformation in the content.\n",
    "        2. Suggest external resources on the topic that would be helpful for increased understanding.\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c3473-e742-41cb-bfbb-3f5e566846a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(client, text, max_tokens=64):\n",
    "    return get_completion(\n",
    "        client,\n",
    "        f\"\"\"Here are the contents of a website: <website>{text}</website>\n",
    "    \n",
    "        Summarize the contents of a website to form a search query that will be used to find related content.\n",
    "        Return only the query itself and nothing else.\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194a00b-c44d-453e-8214-245d8860b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_query(client, scraped_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
