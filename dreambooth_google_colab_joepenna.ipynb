{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab5eS5Zu2538"
      },
      "source": [
        "## Dreambooth\n",
        "#### Colab implementation by David Bielejeski. Latest information on: https://github.com/JoePenna/Dreambooth-Stable-Diffusion\n",
        "##### Before starting, make sure you have the appropriate Accelerator and GPU Type selected from the Runtime menu `Runtime > Change runtime type`.  A minimum of 24GB of VRAM is required so you should select the A100 GPU (40GB). Both the T4 and V100 have less than 20GB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mAmKb7hypxQc",
        "outputId": "e1c94840-59a9-4cac-d3f4-5ed80baf97de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15360 MiB, 15101 MiB\n",
            "\n",
            "\u001b[92mIf the available VRAM is equal or more than 24GB, then you are good to go.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title Check GPU and VRAM available. (Optional)\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "print(\"\\n\\033[92mIf the available VRAM is equal or more than 24GB, then you are good to go.\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V4H7fgwOpxQc",
        "outputId": "c7a58aad-6c3b-42df-869c-3948c5306f61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dreambooth-Stable-Diffusion'...\n",
            "remote: Enumerating objects: 1432, done.\u001b[K\n",
            "remote: Counting objects: 100% (557/557), done.\u001b[K\n",
            "remote: Compressing objects: 100% (222/222), done.\u001b[K\n",
            "remote: Total 1432 (delta 350), reused 505 (delta 334), pack-reused 875 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1432/1432), 17.16 MiB | 12.52 MiB/s, done.\n",
            "Resolving deltas: 100% (838/838), done.\n",
            "/content/Dreambooth-Stable-Diffusion\n"
          ]
        }
      ],
      "source": [
        "#@title 1. Clone & Download The Repo\n",
        "!git clone https://github.com/JoePenna/Dreambooth-Stable-Diffusion\n",
        "%cd Dreambooth-Stable-Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeTrc2vOeiNh",
        "outputId": "daaa9eb6-978b-4423-b8fc-b5be44b09760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.1\n",
            "  Downloading numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Downloading numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.16 requires numpy>=1.24, but you have numpy 1.23.1 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.23.1 which is incompatible.\n",
            "bigframes 1.22.0 requires numpy>=1.24.0, but you have numpy 1.23.1 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.23.1 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.1 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.1 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.23.1 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.23.1 which is incompatible.\n",
            "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "604b438d5d624ccbb9b66f18f9507966"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning==1.7.6\n",
            "  Downloading pytorch_lightning-1.7.6-py3-none-any.whl.metadata (27 kB)\n",
            "\u001b[33mWARNING: Ignoring version 1.7.6 of pytorch-lightning since it has invalid metadata:\n",
            "Requested pytorch-lightning==1.7.6 from https://files.pythonhosted.org/packages/f2/22/37c64bd5b426297c71ecbb01ec2d340f013556a973a2cd6cd0aa68cda1ab/pytorch_lightning-1.7.6-py3-none-any.whl has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.9.*)\n",
            "           ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch-lightning==1.7.6 (from versions: 0.0.2, 0.2, 0.2.2, 0.2.3, 0.2.4, 0.2.4.1, 0.2.5, 0.2.5.1, 0.2.5.2, 0.2.6, 0.3, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.4.1, 0.3.5, 0.3.6, 0.3.6.1, 0.3.6.3, 0.3.6.4, 0.3.6.5, 0.3.6.6, 0.3.6.7, 0.3.6.8, 0.3.6.9, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.5, 0.4.6, 0.4.7, 0.4.8, 0.4.9, 0.5.0, 0.5.1, 0.5.1.2, 0.5.1.3, 0.5.2, 0.5.2.1, 0.5.3, 0.5.3.1, 0.5.3.2, 0.5.3.3, 0.6.0, 0.7.1, 0.7.3, 0.7.5, 0.7.6, 0.8.1, 0.8.3, 0.8.4, 0.8.5, 0.9.0, 0.10.0, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.0.7, 1.0.8, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.1.6, 1.1.7, 1.1.8, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.2.5, 1.2.6, 1.2.7, 1.2.8, 1.2.9, 1.2.10, 1.3.0rc1, 1.3.0rc2, 1.3.0rc3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 1.3.6, 1.3.7, 1.3.7.post0, 1.3.8, 1.4.0rc0, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.4.2, 1.4.3, 1.4.4, 1.4.5, 1.4.6, 1.4.7, 1.4.8, 1.4.9, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.5.5, 1.5.6, 1.5.7, 1.5.8, 1.5.9, 1.5.10, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.6.1, 1.6.2, 1.6.3, 1.6.4, 1.6.5, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.7.2, 1.7.3, 1.7.4, 1.7.5, 1.7.6, 1.7.7, 1.8.0rc0, 1.8.0rc1, 1.8.0rc2, 1.8.0, 1.8.0.post1, 1.8.1, 1.8.2, 1.8.3, 1.8.3.post0, 1.8.3.post1, 1.8.3.post2, 1.8.4, 1.8.4.post0, 1.8.5, 1.8.5.post0, 1.8.6, 1.9.0rc0, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.9.4, 1.9.5, 2.0.0rc0, 2.0.0, 2.0.1, 2.0.1.post0, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.0.9.post0, 2.1.0rc0, 2.1.0rc1, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0rc0, 2.2.0, 2.2.0.post0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.4.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch-lightning==1.7.6\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting csv-logger\n",
            "  Downloading csv_logger-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading csv_logger-1.3.0-py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: csv-logger\n",
            "Successfully installed csv-logger-1.3.0\n",
            "Collecting torchmetrics==0.11.1\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.1) (1.23.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.1) (2.4.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.1) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==0.11.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics==0.11.1) (1.3.0)\n",
            "Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting torch-fidelity==0.3.0\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (1.23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (10.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (1.13.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-fidelity==0.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-fidelity==0.3.0) (1.3.0)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n"
          ]
        }
      ],
      "source": [
        "#@title 2. Build The Environment\n",
        "#@markdown You might get warnings about restarting the runtime. Do this from the Runtime menu and after restarting, resume from Cell.\n",
        "# !pip install numpy==1.23.1\n",
        "!pip install pytorch-lightning==1.7.6\n",
        "!pip install csv-logger\n",
        "!pip install torchmetrics==0.11.1\n",
        "!pip install torch-fidelity==0.3.0\n",
        "!pip install albumentations==1.1.0\n",
        "!pip install opencv-python==4.7.0.72\n",
        "!pip install pudb==2019.2\n",
        "!pip install omegaconf==2.1.1\n",
        "!pip install pillow==9.4.0\n",
        "!pip install einops==0.4.1\n",
        "!pip install transformers==4.25.1\n",
        "!pip install kornia==0.6.7\n",
        "!pip install diffusers[training]==0.3.0\n",
        "!pip install captionizer==1.0.1\n",
        "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -e .\n",
        "!pip install huggingface_hub\n",
        "!pip install gitpython\n",
        "\n",
        "import os\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsODnXyYpxQf"
      },
      "outputs": [],
      "source": [
        "#@title 3. Just to ensure you are in the right directory.\n",
        "%cd Dreambooth-Stable-Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O15vMMhCevib"
      },
      "outputs": [],
      "source": [
        "#@title 4. Download the 1.5 SD model with the improved VAE\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "downloaded_model_path = hf_hub_download(\n",
        " repo_id=\"panopstor/EveryDream\",\n",
        " filename=\"sd_v1-5_vae.ckpt\"\n",
        ")\n",
        "\n",
        "# Move the sd_v1-5_vae.ckpt to the root of this directory as \"model.ckpt\"\n",
        "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
        "!mv {actual_locations_of_model_blob[-1]} model.ckpt\n",
        "clear_output()\n",
        "print(\"✅ model.ckpt successfully downloaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N96aedTtfBjO"
      },
      "outputs": [],
      "source": [
        "#@title 5. Download Regularization Images\n",
        "#@markdown We’ve created the following image sets\n",
        "#@markdown - `man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
        "#@markdown - `man_unsplash` - pictures from various photographers\n",
        "#@markdown - `person_ddim`\n",
        "#@markdown - `woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
        "#@markdown - `artstyle` - provided by Hackmans - ddim @ 50 steps, CFG 10.0 <br />\n",
        "\n",
        "dataset=\"person_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"artstyle\"]\n",
        "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
        "\n",
        "!mkdir -p regularization_images/{dataset}\n",
        "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset}\n",
        "\n",
        "# remove temp folder now it is empty.\n",
        "!rm -rf Stable-Diffusion-Regularization-Images-{dataset}\n",
        "\n",
        "clear_output()\n",
        "print(\"✅ \\033[92mRegularization Images downloaded.\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7hmdOdOfGzs"
      },
      "outputs": [],
      "source": [
        "#@title 6. Training Images\n",
        "#@markdown ## Upload your training images\n",
        "#@markdown WARNING: Be sure to upload an even amount of images, otherwise the training inexplicably stops at 1500 steps. <br />\n",
        "#@markdown - 2-3 full body\n",
        "#@markdown - 3-5 upper body\n",
        "#@markdown - 5-12 close-up on face  <br /> <br />\n",
        "#@markdown The images should be as close as possible to the kind of images you’re trying to make (most of the time, that means no selfies).<br /><br />\n",
        "#@markdown If you get an error during uploading, just manually drag your training images into the training_images folder.\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Create the directory\n",
        "!rm -rf training_images\n",
        "!mkdir -p training_images\n",
        "\n",
        "# Upload the files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        " updated_file_name = filename.replace(\" \", \"_\")\n",
        " !mv \"{filename}\" \"training_images/{updated_file_name}\"\n",
        " clear_output()\n",
        "\n",
        "# Tell the user what is going on\n",
        "training_images_file_paths = !find training_images/*\n",
        "if len(training_images_file_paths) == 0:\n",
        " print(\"❌ \\033[91mno training images found. Please upload images to training_images.\\033[0m\")\n",
        "else:\n",
        " print(\"✅ \\033[92m\" + str(len(training_images_file_paths)) + \" training images found.\\033[0m\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2o_fFFvfxHi"
      },
      "outputs": [],
      "source": [
        "#@title 7. Final Setup & Training\n",
        "\n",
        "#@markdown This isn't used for training, just used to name the folders etc\n",
        "project_name = \"project_name\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown This is the unique token i.e. you can use a nonsensical word like zwx or your name.\n",
        "token = \"firstNamelastName\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Match class_word to the category of the regularization images you chose above.\n",
        "class_word = \"person\" #@param [\"man\", \"person\", \"woman\"] {allow-input: true}\n",
        "\n",
        "# MAX STEPS\n",
        "#@markdown How many steps do you want to train for?\n",
        "max_training_steps = 2000 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown If you are training a person's face, set this to True\n",
        "i_am_training_a_persons_face = True #@param {type:\"boolean\"}\n",
        "flip_p_arg = 0.0 if i_am_training_a_persons_face else 0.5\n",
        "\n",
        "#@markdown Would you like to save a model every X steps? (Example: 250 would output a trained model at 250, 500, 750 steps, etc)\n",
        "save_every_x_steps = 0 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "reg_data_root = \"/content/Dreambooth-Stable-Diffusion/regularization_images/\" + dataset\n",
        "\n",
        "!rm -rf training_images/.ipynb_checkpoints\n",
        "!python \"main.py\" \\\n",
        " --project_name \"{project_name}\" \\\n",
        " --debug False \\\n",
        " --max_training_steps {max_training_steps} \\\n",
        " --token \"{token}\" \\\n",
        " --training_model \"model.ckpt\" \\\n",
        " --training_images \"/content/Dreambooth-Stable-Diffusion/training_images\" \\\n",
        " --regularization_images \"{reg_data_root}\" \\\n",
        " --class_word \"{class_word}\" \\\n",
        " --flip_p {flip_p_arg} \\\n",
        " --save_every_x_steps {save_every_x_steps}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkidEm4evn1J"
      },
      "outputs": [],
      "source": [
        "#@title 8. Save model into google drive\n",
        "#@markdown This is often much faster than a manual download.  it will also save you compute units. <br />\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# copy all ckpt files to google drive root dir\n",
        "!cp trained_models/*.ckpt /content/drive/MyDrive"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}